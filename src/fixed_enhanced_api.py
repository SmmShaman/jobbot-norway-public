#!/usr/bin/env python3
from flask import Flask, jsonify, request
import sys
import os
import json
import requests
from bs4 import BeautifulSoup
from datetime import datetime

sys.path.append('/app/src')
app = Flask(__name__)

def load_azure_config():
    config = {}
    try:
        with open('/app/.env', 'r') as f:
            for line in f:
                if '=' in line and not line.startswith('#'):
                    key, value = line.strip().split('=', 1)
                    config[key] = value
    except:
        pass
    return config

azure_config = load_azure_config()

@app.route('/api/health', methods=['GET'])
def health_check():
    return jsonify({"status": "healthy", "message": "Fixed Enhanced JobBot API"})

@app.route('/api/users', methods=['GET'])
def get_users():
    users_dir = '/app/data/users'
    if os.path.exists(users_dir):
        users = [d for d in os.listdir(users_dir) if os.path.isdir(os.path.join(users_dir, d))]
        return jsonify({"users": users, "status": "success"})
    return jsonify({"users": [], "status": "no_users_found"})

@app.route('/api/jobs/<username>', methods=['GET'])
def find_jobs_real(username):
    """–í–ò–ü–†–ê–í–õ–ï–ù–ò–ô —Ä–µ–∞–ª—å–Ω–∏–π –ø–æ—à—É–∫ –≤–∞–∫–∞–Ω—Å—ñ–π + AI –∞–Ω–∞–ª—ñ–∑"""
    try:
        print(f"üîç Starting FIXED job search for {username}")
        
        # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∫–æ–Ω—Ñ—ñ–≥ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        user_config = load_user_config(username)
        if not user_config:
            return jsonify({"error": "User config not found", "jobs": []})
        
        # 2. –°–∫—Ä–∞–ø–∏—Ç–∏ arbeidsplassen.nav.no –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏
        jobs = scrape_nav_jobs_fixed(user_config)
        print(f"üìä Found {len(jobs)} jobs from NAV")
        
        # 3. AI –∞–Ω–∞–ª—ñ–∑ –∫–æ–∂–Ω–æ—ó –≤–∞–∫–∞–Ω—Å—ñ—ó
        analyzed_jobs = []
        for i, job in enumerate(jobs[:5]):  # –û–±–º–µ–∂–∏—Ç–∏ 5 –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
            print(f"ü§ñ Analyzing job {i+1}: {job['title']}")
            analysis = analyze_job_with_ai(job, user_config, username)
            job.update(analysis)
            analyzed_jobs.append(job)
        
        # 4. –°–æ—Ä—Ç—É–≤–∞—Ç–∏ –∑–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—é
        analyzed_jobs.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        # 5. –ó–±–µ—Ä–µ–≥—Ç–∏ –≤ Google Sheets (–º–æ–∫–∞–ø –ø–æ–∫–∏)
        save_to_sheets_log(username, analyzed_jobs)
        
        return jsonify({
            "username": username,
            "jobs": analyzed_jobs,
            "jobs_found": len(analyzed_jobs),
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå Error in find_jobs_real: {e}")
        return jsonify({"error": str(e), "jobs": []})

def load_user_config(username):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∫–æ–Ω—Ñ—ñ–≥ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞"""
    try:
        config_path = f'/app/data/users/{username}/config.json'
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ùå Error loading config for {username}: {e}")
        return None

def scrape_nav_jobs_fixed(user_config):
    """–í–ò–ü–†–ê–í–õ–ï–ù–ò–ô scraper –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏"""
    jobs = []
    
    # URL –¥–ª—è √òstre Toten + Vestre Toten
    nav_url = "https://arbeidsplassen.nav.no/stillinger?county=INNLANDET&v=5&municipal=INNLANDET.%C3%98STRE+TOTEN&municipal=INNLANDET.VESTRE+TOTEN"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        response = requests.get(nav_url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –ó–Ω–∞–π—Ç–∏ –≤—Å—ñ —Å—Ç–∞—Ç—Ç—ñ
        job_articles = soup.find_all('article')
        print(f"üîç Found {len(job_articles)} articles")
        
        for i, article in enumerate(job_articles[:10]):  # –û–±–º–µ–∂–∏—Ç–∏ 10 –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
            try:
                # –ù–∞–∑–≤–∞ –≤–∞–∫–∞–Ω—Å—ñ—ó - h2 —Ç–µ–≥
                title_elem = article.find('h2')
                title = title_elem.get_text(strip=True) if title_elem else f"Job {i+1}"
                
                # –ö–æ–º–ø–∞–Ω—ñ—è - –ø–æ—à—É–∫ –≤ aria-label –∞–±–æ —Ç–µ–∫—Å—Ç—ñ
                aria_label = article.get('aria-label', '')
                company = "Unknown company"
                if ', ' in aria_label:
                    parts = aria_label.split(', ')
                    if len(parts) >= 2:
                        company = parts[1]
                
                # –ü–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –≤–∞–∫–∞–Ω—Å—ñ—é
                link_elem = article.find('a', href=True)
                job_url = ""
                if link_elem:
                    href = link_elem['href']
                    if href.startswith('/'):
                        job_url = "https://arbeidsplassen.nav.no" + href
                    else:
                        job_url = href
                
                # –õ–æ–∫–∞—Ü—ñ—è –∑ aria-label
                location = "√òstre Toten / Vestre Toten"
                if len(aria_label.split(', ')) >= 3:
                    location = aria_label.split(', ')[2]
                
                job_data = {
                    'title': title,
                    'company': company,
                    'location': location,
                    'url': job_url,
                    'source': 'arbeidsplassen.nav.no',
                    'scraped_at': datetime.now().isoformat(),
                    'aria_label': aria_label  # –î–ª—è debug
                }
                
                jobs.append(job_data)
                print(f"‚úÖ Job {i+1}: {title} at {company}")
                
            except Exception as e:
                print(f"‚ö†Ô∏è Error parsing job {i+1}: {e}")
                continue
        
        print(f"‚úÖ Successfully scraped {len(jobs)} jobs from NAV")
        return jobs
        
    except Exception as e:
        print(f"‚ùå Error scraping NAV: {e}")
        return []

def analyze_job_with_ai(job, user_config, username):
    """AI –∞–Ω–∞–ª—ñ–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—ñ –≤–∞–∫–∞–Ω—Å—ñ—ó"""
    try:
        user_info = user_config.get('user_info', {})
        
        # Prompt –¥–ª—è Azure OpenAI
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π—Ç–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—å –≤–∞–∫–∞–Ω—Å—ñ—ó –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –≤ –ù–æ—Ä–≤–µ–≥—ñ—ó:

–í–ê–ö–ê–ù–°–Ü–Ø:
–ù–∞–∑–≤–∞: {job['title']}
–ö–æ–º–ø–∞–Ω—ñ—è: {job['company']}
–õ–æ–∫–∞—Ü—ñ—è: {job['location']}

–ö–ê–ù–î–ò–î–ê–¢ ({username}):
–Ü–º'—è: {user_info.get('full_name', 'N/A')}
–ü–æ—Ç–æ—á–Ω–∞ –ø–æ–∑–∏—Ü—ñ—è: {user_info.get('current_position', 'N/A')}
–ù–∞–≤–∏—á–∫–∏: {', '.join(user_info.get('skills', []))}
–û—Å–≤—ñ—Ç–∞: {user_info.get('education', 'N/A')}
–ú–æ–≤–∏: {', '.join(user_info.get('languages', []))}
–î–æ—Å–≤—ñ–¥: {user_info.get('years_experience', 'N/A')}

–ó–ê–í–î–ê–ù–ù–Ø:
–û—Ü—ñ–Ω—ñ—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—å –≤—ñ–¥ 0 –¥–æ 100 —Ç–∞ –¥–∞–π—Ç–µ –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–µ–Ω—Ç–∞—Ä —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é.

–§–û–†–ú–ê–¢ –í–Ü–î–ü–û–í–Ü–î–Ü JSON:
{{
  "relevance_score": 85,
  "reasoning": "–ö–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–µ–Ω—Ç–∞—Ä —á–æ–º—É —Ç–∞–∫–∞ –æ—Ü—ñ–Ω–∫–∞",
  "key_matches": ["Python", "Management"],
  "recommendation": "APPLY"
}}"""

        # –í–∏–∫–ª–∏–∫–∞—Ç–∏ Azure OpenAI
        ai_response = call_azure_openai(prompt)
        
        try:
            # –û—á–∏—Å—Ç–∏—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ –º–æ–∂–ª–∏–≤–∏—Ö markdown –±–ª–æ–∫—ñ–≤
            clean_response = ai_response.strip()
            if clean_response.startswith('```json'):
                clean_response = clean_response[7:]
            if clean_response.endswith('```'):
                clean_response = clean_response[:-3]
            
            result = json.loads(clean_response)
            return {
                'relevance_score': result.get('relevance_score', 50),
                'ai_reasoning': result.get('reasoning', 'AI analysis completed'),
                'key_matches': result.get('key_matches', []),
                'recommendation': result.get('recommendation', 'REVIEW')
            }
        except Exception as parse_error:
            print(f"‚ö†Ô∏è JSON parse error: {parse_error}")
            print(f"Raw AI response: {ai_response[:200]}...")
            # Fallback –∞–Ω–∞–ª—ñ–∑
            return {
                'relevance_score': 60,
                'ai_reasoning': 'AI analysis completed (JSON parse error)',
                'key_matches': [],
                'recommendation': 'REVIEW'
            }
            
    except Exception as e:
        print(f"‚ùå AI analysis error: {e}")
        return {
            'relevance_score': 50,
            'ai_reasoning': f'Error: {str(e)}',
            'key_matches': [],
            'recommendation': 'REVIEW'
        }

def call_azure_openai(prompt):
    """–í–∏–∫–ª–∏–∫–∞—Ç–∏ Azure OpenAI API"""
    try:
        endpoint = azure_config.get('OPENAI_ENDPOINT', '').rstrip('/')
        key = azure_config.get('OPENAI_KEY', '')
        deployment = azure_config.get('AZURE_OPENAI_DEPLOYMENT_CHAT', '')
        
        if not all([endpoint, key, deployment]):
            return '{"relevance_score": 50, "reasoning": "Azure config missing"}'
        
        url = f"{endpoint}/openai/deployments/{deployment}/chat/completions?api-version=2024-02-01"
        
        headers = {
            "Content-Type": "application/json",
            "api-key": key
        }
        
        payload = {
            "messages": [
                {"role": "system", "content": "–í–∏ –µ–∫—Å–ø–µ—Ä—Ç –∑ –∞–Ω–∞–ª—ñ–∑—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—ñ –≤–∞–∫–∞–Ω—Å—ñ–π –≤ –ù–æ—Ä–≤–µ–≥—ñ—ó. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π—Ç–µ —Ç—ñ–ª—å–∫–∏ JSON –±–µ–∑ –¥–æ–¥–∞—Ç–∫–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç—É."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 500,
            "temperature": 0.3
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            return data['choices'][0]['message']['content'].strip()
        else:
            print(f"‚ùå Azure API error: {response.status_code}")
            return '{"relevance_score": 50, "reasoning": "API error"}'
            
    except Exception as e:
        print(f"‚ùå Azure API exception: {e}")
        return f'{{"relevance_score": 50, "reasoning": "Exception: {str(e)}"}}'

def save_to_sheets_log(username, jobs):
    """–ó–±–µ—Ä–µ–≥—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤ –ª–æ–∫–∞–ª—å–Ω–∏–π –ª–æ–≥"""
    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = f'/app/data/sheets_log_{username}_{timestamp}.json'
        
        log_data = []
        for job in jobs:
            log_entry = {
                'timestamp': datetime.now().isoformat(),
                'candidate': username,
                'job_title': job['title'],
                'company': job['company'],
                'location': job['location'],
                'relevance_score': f"{job.get('relevance_score', 0)}%",
                'ai_reasoning': job.get('ai_reasoning', ''),
                'key_matches': ', '.join(job.get('key_matches', [])),
                'recommendation': job.get('recommendation', 'REVIEW'),
                'applied': 'No',
                'application_status': 'Analyzed',
                'job_url': job['url']
            }
            log_data.append(log_entry)
        
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Saved {len(log_data)} jobs to {log_file}")
        
    except Exception as e:
        print(f"‚ùå Error saving to sheets log: {e}")

@app.route('/api/workflow/<username>', methods=['POST'])
def run_workflow_real(username):
    """–†–ï–ê–õ–¨–ù–ò–ô workflow: form filling + NAV reporting"""
    try:
        return jsonify({
            "status": "success",
            "username": username,
            "message": "Real workflow - TODO: integrate form filler",
            "applied_jobs": 0,
            "nav_reported": False
        })
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)})

if __name__ == '__main__':
    print('üöÄ Starting FIXED Enhanced JobBot API server...')
    print('‚úÖ Real scraping + AI analysis with CORRECT selectors')
    app.run(host='0.0.0.0', port=3000, debug=True)
